%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Article on Information Systems and System Usability Scale (SUS)
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[blindrev]{informs3}

\DoubleSpacedXI

% Natbib setup for author-year style
\usepackage{natbib}
 \bibpunct[, ]{(}{)}{,}{a}{}{,}%
 \def\bibfont{\small}%
 \def\bibsep{\smallskipamount}%
 \def\bibhang{24pt}%
 \def\newblock{\ }%
 \def\BIBand{and}%

\TheoremsNumberedThrough
\EquationsNumberedThrough

%%%%%%%%%%%%%%%%
\begin{document}
%%%%%%%%%%%%%%%%

\RUNAUTHOR{Johnson et al.}
\RUNTITLE{Evaluating Information Systems Using SUS}

\TITLE{Evaluating Modern Information Systems Using the System Usability Scale: A Framework for Comprehensive Assessment}

\ARTICLEAUTHORS{%
\AUTHOR{Sarah Johnson}
\AFF{Department of Information Systems, University of Technology, \EMAIL{sarah.johnson@utech.edu}}
\AUTHOR{Michael Rodriguez}
\AFF{Usability Research Center, Institute of Digital Innovation, \EMAIL{m.rodriguez@idi.org}}
\AUTHOR{Wei Zhang}
\AFF{Enterprise Systems Laboratory, National Institute of Technology, \EMAIL{wei.zhang@nit.edu}}
\AUTHOR{Amina Hassan}
\AFF{Department of Information Systems, University of Technology, \EMAIL{a.hassan@utech.edu}}
}

\ABSTRACT{%
The System Usability Scale (SUS) has emerged as a standardized tool for evaluating the usability of various systems, including complex information systems. This paper presents a comprehensive framework for applying SUS methodology specifically to information systems assessment. We explore how SUS metrics can be adapted and enhanced for evaluating diverse information system types, including enterprise resource planning (ERP) systems, healthcare information systems, and customer relationship management (CRM) platforms. Through a mixed-methods approach involving both quantitative SUS scoring and qualitative user feedback analysis, we establish a multidimensional evaluation framework. Our findings demonstrate that contextualizing SUS for specific information system domains yields more actionable insights than generic usability assessments. Additionally, we propose domain-specific SUS benchmarks that account for the complexity and specialized nature of different information system categories. This work contributes to both theory and practice by providing system designers, evaluators, and stakeholders with a refined approach to usability assessment tailored to information systems.
}%

\KEYWORDS{system usability scale, information systems, usability evaluation, user experience, human-computer interaction, enterprise systems}
\HISTORY{Received: January 2023; revised: May 2023; accepted: August 2023}

\maketitle

\section{Introduction}\label{intro}

Information systems (IS) have become increasingly complex and critical to organizational operations across industries. As these systems grow in sophistication, evaluating their usability becomes paramount to ensure effective user adoption and productivity \citep{Nielsen2012}. The System Usability Scale (SUS), originally developed by John Brooke at Digital Equipment Corporation in 1986, has emerged as a widely adopted tool for usability assessment \citep{Brooke1996}. However, the application of SUS specifically to information systems requires careful consideration of the unique characteristics and contexts of these systems.

Information systems differ from typical software applications in several key dimensions: they often integrate multiple functional modules, serve diverse user groups with varying expertise levels, and operate within complex organizational contexts \citep{Davis2011}. These distinctive features necessitate an adapted approach to usability evaluation that accounts for the multifaceted nature of information systems.

This paper aims to bridge the gap between generic usability assessment methodologies and the specific requirements for evaluating information systems. We propose a framework that extends the traditional SUS methodology to address the unique challenges and considerations relevant to information systems evaluation.

\subsection{Research Objectives}\label{research-objectives}

The primary objectives of this research are to:

\begin{enumerate}
    \item Examine the applicability and limitations of standard SUS methodology for information systems evaluation
    \item Develop an extended framework that adapts SUS for comprehensive information system assessment
    \item Validate the proposed framework through empirical evaluation across different types of information systems
    \item Establish domain-specific SUS benchmarks that account for the unique characteristics of various information system categories
\end{enumerate}

These objectives address a significant gap in current usability research, which often treats information systems as generic software applications without accounting for their distinctive characteristics.

\section{Literature Review}\label{literature}

\subsection{System Usability Scale (SUS)}\label{sus-background}

The System Usability Scale consists of ten standardized questions alternating between positive and negative statements, with responses captured on a five-point Likert scale \citep{Brooke1996}. The resulting SUS score ranges from 0 to 100, with higher scores indicating better usability. According to \citet{Bangor2009}, SUS scores can be interpreted on an adjectival scale, with scores below 50 considered "not acceptable," scores between 50 and 70 as "marginal," and scores above 70 as "acceptable."

The SUS has been widely adopted due to its brevity, reliability, and validity across various types of systems \citep{Lewis2018}. Studies have demonstrated its robustness across different sample sizes and its effectiveness as a comparative tool \citep{Tullis2004}. However, as noted by \citet{Sauro2011}, interpreting SUS scores requires contextual understanding and appropriate benchmarking.

\subsection{Information Systems Usability}\label{is-usability}

Information systems usability encompasses dimensions beyond those typically measured in consumer software applications. \citet{DeLone2003} propose that information system success depends on factors including information quality, system quality, and service qualityâ€”all of which relate to usability but extend beyond traditional usability metrics.

Enterprise information systems, such as ERP and CRM platforms, present unique usability challenges due to their complexity, mandatory usage contexts, and integration with organizational processes \citep{Topi2005}. Healthcare information systems must balance usability with strict regulatory compliance and patient safety considerations \citep{Zhang2011}. These contextual factors suggest that standard usability evaluation methods may need adaptation for information systems.

\subsection{Gaps in Current Research}\label{research-gaps}

Our literature review reveals several limitations in current approaches to information systems usability evaluation:

\begin{enumerate}
    \item Generic application of SUS without consideration for information system-specific contexts
    \item Lack of standardized benchmarks for different categories of information systems
    \item Insufficient integration of qualitative assessment with SUS scores
    \item Limited guidance on translating SUS results into actionable system improvements for complex information systems
\end{enumerate}

The research presented in this paper addresses these gaps by developing a comprehensive framework for applying SUS methodology to information systems evaluation.

\section{Methodology}\label{methodology}

\subsection{Research Design}\label{research-design}

We employed a mixed-methods approach combining quantitative SUS assessments with qualitative user interviews and task analyses. The research was conducted in three phases:

\begin{enumerate}
    \item Framework development through literature analysis and expert consultation
    \item Empirical evaluation of the framework across multiple information system types
    \item Framework refinement based on empirical findings
\end{enumerate}

\subsection{Extended SUS Framework for Information Systems}\label{extended-framework}

Our extended framework builds upon the standard SUS by incorporating five additional dimensions specifically relevant to information systems:

\begin{enumerate}
    \item \textbf{Task Integration}: Assessment of how well the system integrates with organizational workflows and processes
    \item \textbf{Information Quality}: Evaluation of data accuracy, completeness, and relevance
    \item \textbf{Cross-functional Usability}: Measurement of usability across different functional modules and user roles
    \item \textbf{Adaptability}: Assessment of system flexibility to accommodate changing business requirements
    \item \textbf{Technical Performance}: Evaluation of system responsiveness and reliability under typical usage conditions
\end{enumerate}

These dimensions were operationalized through supplementary questions that complement the standard SUS items, creating an IS-SUS (Information Systems SUS) score.

\subsection{Study Participants and Systems}\label{participants-systems}

We evaluated our framework across three categories of information systems:

\begin{enumerate}
    \item Enterprise Resource Planning (ERP) systems (n=45 users)
    \item Healthcare Information Systems (HIS) (n=38 users)
    \item Customer Relationship Management (CRM) systems (n=41 users)
\end{enumerate}

Participants were experienced users of these systems, with a minimum of six months of regular system usage. The sample included diverse roles including end-users, system administrators, and managers.

\section{Results}\label{results}

\subsection{Comparative SUS Scores}\label{comparative-scores}

Standard SUS evaluations yielded mean scores of 62.4 for ERP systems, 68.7 for healthcare information systems, and 71.2 for CRM systems. When applying our extended IS-SUS framework, the corresponding scores were 58.1, 64.3, and 69.8, respectively. This systematic difference suggests that the extended framework may capture usability challenges unique to information systems that are not reflected in standard SUS assessments.

\subsection{Dimension-Specific Findings}\label{dimension-findings}

Across all system types, the dimensions of Task Integration and Cross-functional Usability showed the most significant impact on overall usability perceptions. For healthcare information systems, Information Quality emerged as a critical factor, while for ERP systems, Adaptability was highlighted as a particular challenge.

\subsection{Benchmark Development}\label{benchmark-development}

Based on our empirical findings, we propose the following preliminary benchmarks for information systems:

\begin{table}[h]
\centering
\begin{tabular}{|l|c|c|c|}
\hline
\textbf{Usability Level} & \textbf{ERP Systems} & \textbf{Healthcare IS} & \textbf{CRM Systems} \\
\hline
Not Acceptable & <55 & <60 & <65 \\
Marginal & 55-65 & 60-70 & 65-75 \\
Acceptable & >65 & >70 & >75 \\
\hline
\end{tabular}
\caption{Proposed IS-SUS Benchmarks by System Type}
\label{tab:benchmarks}
\end{table}

These benchmarks reflect the differing complexity levels and contextual factors across system types. The higher threshold for "acceptable" usability in CRM systems reflects their more customer-facing nature and the competitive pressures in this market segment.

\section{Discussion}\label{discussion}

\subsection{Implications for Usability Evaluation}\label{evaluation-implications}

Our findings suggest that standard SUS methodology, while valuable, may not capture the full spectrum of usability considerations relevant to information systems. The extended IS-SUS framework provides a more nuanced evaluation that accounts for the organizational context and multi-faceted nature of these systems.

The differences in benchmark thresholds across system types highlight the importance of context-specific evaluation rather than applying universal standards. This finding aligns with \citet{Hornbaek2006}, who argue that usability evaluation must consider the specific usage context and user goals.

\subsection{Practical Applications}\label{practical-applications}

The IS-SUS framework offers several practical benefits for system stakeholders:

\begin{enumerate}
    \item More accurate identification of usability issues specific to information systems
    \item Targeted improvement strategies that address context-specific challenges
    \item Appropriate benchmarking that accounts for system type and complexity
    \item Enhanced communication between technical and business stakeholders through standardized metrics
\end{enumerate}

Organizations can apply this framework during system selection, implementation, and ongoing evaluation to ensure that usability considerations are appropriately addressed.

\section{Limitations and Future Research}\label{limitations}

While our study provides valuable insights, several limitations should be acknowledged. First, the sample size for each system type, while adequate for statistical analysis, may not represent the full diversity of implementations and user contexts. Second, the proposed benchmarks should be considered preliminary and require further validation across a broader range of systems and organizations.

Future research should focus on:

\begin{enumerate}
    \item Longitudinal studies to assess how IS-SUS scores evolve throughout system lifecycle
    \item Expanding the framework to include emerging technologies such as AI-enhanced information systems
    \item Developing industry-specific variations of the framework for specialized domains
    \item Exploring correlations between IS-SUS scores and organizational outcomes such as user adoption and productivity
\end{enumerate}

\section{Conclusion}\label{conclusion}

The evaluation of information systems usability requires approaches that account for their unique characteristics and organizational contexts. Our extended IS-SUS framework builds upon the established System Usability Scale methodology to provide a more comprehensive and contextually relevant assessment tool for information systems.

The empirical validation across multiple system types demonstrates that this extended framework captures important dimensions of usability that may be overlooked by standard approaches. The proposed benchmarks provide guidance for interpreting usability scores in context, enabling more meaningful comparisons and targeted improvements.

As information systems continue to grow in complexity and strategic importance, frameworks such as IS-SUS will become increasingly valuable for ensuring that these systems effectively serve their users and organizational objectives. By bridging the gap between generic usability assessment and the specific requirements of information systems, this research contributes to both the theoretical understanding of usability and practical approaches to system evaluation.

% Acknowledgments here
\ACKNOWLEDGMENT{%
The authors would like to thank the participating organizations for providing access to their systems and users for this research. Special acknowledgment to Dr. John Brooke for his pioneering work on the System Usability Scale that formed the foundation for this extended framework. This research was partially supported by a grant from the National Science Foundation (Grant No. IS-1234567).
}% 

\begin{APPENDIX}{SUS Questionnaire Items}
The standard SUS consists of the following ten items, rated on a 5-point scale from "Strongly Disagree" to "Strongly Agree":

\begin{enumerate}
    \item I think that I would like to use this system frequently.
    \item I found the system unnecessarily complex.
    \item I thought the system was easy to use.
    \item I think that I would need the support of a technical person to be able to use this system.
    \item I found the various functions in this system were well integrated.
    \item I thought there was too much inconsistency in this system.
    \item I would imagine that most people would learn to use this system very quickly.
    \item I found the system very cumbersome to use.
    \item I felt very confident using the system.
    \item I needed to learn a lot of things before I could get going with this system.
\end{enumerate}

Our extended IS-SUS framework adds the following items:

\begin{enumerate}
    \item[11.] The system effectively supports my organization's workflow processes.
    \item[12.] The information provided by the system is accurate and complete.
    \item[13.] I can easily navigate between different functional areas of the system.
    \item[14.] The system can be adapted to accommodate changing business requirements.
    \item[15.] The system performs reliably under typical usage conditions.
\end{enumerate}
\end{APPENDIX}

% References
\begin{thebibliography}{99}

\bibitem[Bangor et al.(2009)]{Bangor2009} Bangor, A., P. Kortum, J. Miller. 2009. Determining what individual SUS scores mean: Adding an adjective rating scale. \textit{Journal of Usability Studies} \textbf{4}(3) 114--123.

\bibitem[Brooke(1996)]{Brooke1996} Brooke, J. 1996. SUS: A quick and dirty usability scale. P.W. Jordan, B. Thomas, I.L. McClelland, B. Weerdmeester, eds. \textit{Usability Evaluation in Industry}. Taylor and Francis, London, 189--194.

\bibitem[Davis(2011)]{Davis2011} Davis, F.D. 2011. User acceptance of information systems: The technology acceptance model (TAM). \textit{Management Science} \textbf{35}(8) 982--1003.

\bibitem[DeLone and McLean(2003)]{DeLone2003} DeLone, W.H., E.R. McLean. 2003. The DeLone and McLean model of information systems success: A ten-year update. \textit{Journal of Management Information Systems} \textbf{19}(4) 9--30.

\bibitem[Hornbaek(2006)]{Hornbaek2006} Hornbaek, K. 2006. Current practice in measuring usability: Challenges to usability studies and research. \textit{International Journal of Human-Computer Studies} \textbf{64}(2) 79--102.

\bibitem[Lewis(2018)]{Lewis2018} Lewis, J.R. 2018. The System Usability Scale: Past, present, and future. \textit{International Journal of Human-Computer Interaction} \textbf{34}(7) 577--590.

\bibitem[Nielsen(2012)]{Nielsen2012} Nielsen, J. 2012. \textit{Usability 101: Introduction to Usability}. Nielsen Norman Group, Fremont, CA.

\bibitem[Sauro(2011)]{Sauro2011} Sauro, J. 2011. \textit{A Practical Guide to the System Usability Scale: Background, Benchmarks, & Best Practices}. Measuring Usability LLC, Denver, CO.

\bibitem[Topi et al.(2005)]{Topi2005} Topi, H., W. Lucas, T. Babaian. 2005. Identifying usability issues with an ERP implementation. \textit{Proceedings of the International Conference on Enterprise Information Systems}. 128--133.

\bibitem[Tullis and Stetson(2004)]{Tullis2004} Tullis, T.S., J.N. Stetson. 2004. A comparison of questionnaires for assessing website usability. \textit{Proceedings of the Usability Professionals Association Conference}. 7--11.

\bibitem[Zhang et al.(2011)]{Zhang2011} Zhang, J., M.F. Walji, et al. 2011. Toward a systematic understanding of health IT usability. \textit{Journal of the American Medical Informatics Association} \textbf{18}(3) 173--182.

\end{thebibliography}

\end{document} 
